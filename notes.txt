This are going to be all the note of the project, including all the concepts required and 
some specific concepts related to the project and the area

Initialy, we have to install with Pip commands the library Scrapy, so, then to start 
correctly our project we need to use the next command to create the enviroment of the project
within our corrent path

$ scrapy startproject ietf_scraper
"scrapy command - sentence - name of the project"

Then to do this, we need to focus on the Spyder's folder, actually, a web scraper is defined 
by many spyders, so, to configure automatically this folder we can follow the next command in cmd
-Remember to stay in the Spyder path

$ scrapy genspider ietf pythonscraping.com
"scrapy command - generate spider folder - name of the folder - the main domain"

this is to connect with the domain of the framework and creates a tamplate of our first spider

This course will use XPATH to create the selectors, so one sentence within the pasre function could be the next

    'number': response.xpath('//span[@class="rfc-no"]/text()').get(), 
    'title': response.xpath('//span[@name="DC.Title"]/@content').get(), 

so, to get the text content of the tag we use "/text()"
to get the value eithin the tag we use "@content"


*********Second Project - WIKIPEDIA
first, i created the new project using "startproject", then in the folder Spider i created the correspond files
using "genspider". 

So, within the Spider/wikipedia.py, first we need to EXTEND SCRAPY'S CLASS 

Before: 
class WikipediaSpider(scrapy.Spider):

After: 
class WikipediaSpider(CrawlSpider):
And mus import this library 
from scrapy.spiders import CrawlSpider

The difference between a scraper and a crawler is that the crawler need to spacify some rules 
We need to give rules for the links to follow, we can do it by using a scrapy rule object


Items
An item is a type of content, we have to modify our file items.py file by adding new objects
If we want to use items, in the file we must write what are going to be those ones, like this

    class ArticleScraperItem(scrapy.Item):
        title = scrapy.Field()
        url = scrapy.Field()

And, it is also necesary to modify the Parse file

then ,to run correctly the file we need to use this command in the cmd
    scrapy runspider wikipedia.py -o articles.csv -t csv -s CLOSESPIDER_PAGECOUNT=10

Setting
in the past lesson we needed to use the final command "CLOSESPIDER_PAGECOUNT=10", this could be
better if we set this information or this parameter inside some place, that place is going to be 
the setting.py file which also we can find the BOT_NAME parameter





























